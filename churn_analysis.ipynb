{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "print(\"Initial shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Duplicate rows found: {duplicates}\")\n",
        "df = df.drop_duplicates()\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.boxplot(x=df[\"TotalCharges\"])\n",
        "plt.title(\"Boxplot - Outlier Check for TotalCharges\")\n",
        "plt.show()\n",
        "if \"customerID\" in df.columns:\n",
        "    df = df.drop(columns=[\"customerID\"])\n",
        "df[\"Churn\"] = df[\"Churn\"].map({\"No\": 0, \"Yes\": 1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 4))\n",
        "sns.countplot(x=\"Churn\", data=df)\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.hist(df[\"tenure\"], bins=30, edgecolor=\"black\")\n",
        "plt.title(\"Tenure Distribution\")\n",
        "plt.xlabel(\"Tenure (months)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "print(\"Numeric features:\", numeric_features)\n",
        "print(\"Categorical features:\", categorical_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "km_imputer = SimpleImputer(strategy='median')\n",
        "scaler_km = StandardScaler()\n",
        "X_train_num = km_imputer.fit_transform(X_train[numeric_features])\n",
        "X_train_scaled = scaler_km.fit_transform(X_train_num)\n",
        "X_test_num = km_imputer.transform(X_test[numeric_features])\n",
        "X_test_scaled = scaler_km.transform(X_test_num)\n",
        "inertia = []\n",
        "K_range = range(1, 10)\n",
        "for k in K_range:\n",
        "    kmeans_test = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    kmeans_test.fit(X_train_scaled)\n",
        "    inertia.append(kmeans_test.inertia_)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(K_range, inertia, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "kmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
        "X_train = X_train.copy()\n",
        "X_test = X_test.copy()\n",
        "X_train[\"cluster\"] = kmeans.fit_predict(X_train_scaled)\n",
        "X_test[\"cluster\"] = kmeans.predict(X_test_scaled)\n",
        "X_train[\"cluster\"] = X_train[\"cluster\"].astype(str)\n",
        "X_test[\"cluster\"] = X_test[\"cluster\"].astype(str)\n",
        "categorical_features_with_cluster = categorical_features + [\"cluster\"]\n",
        "print(\"Cluster feature created.\")\n",
        "print(\"Updated Categorical features:\", categorical_features_with_cluster)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features_with_cluster),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "def evaluate_model(model, name, X_tr, y_tr, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    f1 = f1_score(y_te, y_pred)\n",
        "    recall = recall_score(y_te, y_pred)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Accuracy: {acc:.4f} | F1: {f1:.4f} | Recall: {recall:.4f}\")\n",
        "    return {\"Model\": name, \"Accuracy\": acc, \"F1-Score\": f1}\n",
        "pipe_lr = Pipeline([(\"preprocess\", preprocessor), (\"clf\", LogisticRegression(max_iter=1000))])\n",
        "results.append(evaluate_model(pipe_lr, \"LogReg (Baseline)\", X_train, y_train, X_test, y_test))\n",
        "pipe_knn = Pipeline([(\"preprocess\", preprocessor), (\"clf\", KNeighborsClassifier(n_neighbors=5))])\n",
        "results.append(evaluate_model(pipe_knn, \"KNN\", X_train, y_train, X_test, y_test))\n",
        "pipe_rf = Pipeline([(\"preprocess\", preprocessor), (\"clf\", RandomForestClassifier(random_state=42))])\n",
        "results.append(evaluate_model(pipe_rf, \"RandomForest (Baseline)\", X_train, y_train, X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_lr = {'clf__C': [0.1, 1.0, 10.0]}\n",
        "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, cv=5, scoring='f1', n_jobs=-1)\n",
        "results.append(evaluate_model(grid_lr, \"LogReg (Tuned)\", X_train, y_train, X_test, y_test))\n",
        "best_lr = grid_lr.best_estimator_\n",
        "y_pred_best_lr = best_lr.predict(X_test)\n",
        "cm_lr = confusion_matrix(y_test, y_pred_best_lr)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm_lr, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix - Tuned Logistic Regression\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()\n",
        "false_negatives = cm_lr[1, 0]\n",
        "avg_monthly_charge = df['MonthlyCharges'].mean()\n",
        "revenue_risk = false_negatives * avg_monthly_charge\n",
        "print(f\"\\n--- Business Impact Analysis ---\")\n",
        "print(f\"False Negatives (Missed Churners): {false_negatives}\")\n",
        "print(f\"Average Monthly Charge: ${avg_monthly_charge:.2f}\")\n",
        "print(f\"Estimated Monthly Revenue at Risk: ${revenue_risk:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_rf = {\n",
        "    'clf__n_estimators': [100, 200],\n",
        "    'clf__max_depth': [10, None]\n",
        "}\n",
        "grid_rf = GridSearchCV(pipe_rf, param_grid_rf, cv=5, scoring='f1', n_jobs=-1)\n",
        "results.append(evaluate_model(grid_rf, \"RandomForest (Tuned)\", X_train, y_train, X_test, y_test))\n",
        "best_rf = grid_rf.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    feature_names = best_lr.named_steps[\"preprocess\"].get_feature_names_out()\n",
        "    coefs = best_lr.named_steps[\"clf\"].coef_[0]\n",
        "    coef_df = pd.DataFrame({\"Feature\": feature_names, \"Coefficient\": coefs})\n",
        "    print(\"Top 5 indicators of Churn (Positive Coefs):\")\n",
        "    print(coef_df.sort_values(by=\"Coefficient\", ascending=False).head())\n",
        "    print(\"\\nTop 5 indicators of Retention (Negative Coefs):\")\n",
        "    print(coef_df.sort_values(by=\"Coefficient\", ascending=True).head())\n",
        "except Exception as e:\n",
        "    print(f\"Could not extract coefficients: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"=\" * 60)\n",
        "print(\"Summary (Sorted by F1-Score):\")\n",
        "print(results_df.sort_values(by=\"F1-Score\", ascending=False).reset_index(drop=True))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
